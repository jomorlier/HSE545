{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1. Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 3\n",
    "\n",
    "In this problem, we want to explore a reflection transformation of $X$, which produces a mirror vector $Z$ with respect to vector $V$. See Figure 1.\n",
    "\n",
    "<img src=\"./image_files/LA01.png\", width = 250>\n",
    "<center>Figure 1</center>\n",
    "\n",
    "1) Is a reflection transformation linear?\n",
    "\n",
    "2) If yes, find matrix $M$ such that $Z = MX$ using concept of projection.\n",
    "\n",
    "3) If yes, find matrix $M$ such that $Z = MX$ using concept of eigen values and vectors. (you can use the results of the above problems)\n",
    "\n",
    "3) For $V = \\begin{bmatrix} 1 & 1 \\end{bmatrix}^T$, compute $M$ and its eigenvalues/eigenvectors (here, vector $V$ is a vector with 45 degree angle with x-axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 5\n",
    "\n",
    "Let $R = R(\\theta)$ be a rotation matrix with a rotational angle of $\\theta$ in $\\mathbb{R}^n$.\n",
    "\n",
    "1. Prove that $$R^TR=I \\;\\text{in}\\; \\mathbb{R}^n$$\n",
    "    \n",
    "    Hint: Euclidian distances of vectors are preserved after a rotational operation. (_i.e._, $\\lVert Rx \\rVert = \\lVert x \\rVert$ for any $x \\in \\mathbb{R}^n$ ) \n",
    "<br><br>\n",
    "2. Prove that $$R^T(\\theta) = R^{-1}(\\theta) = R(-\\theta)\\;\\text{in}\\;\\mathbb{R}^n$$\n",
    "<br><br>\n",
    "3. Show that column vectors in $R$ are orthogonal in $\\mathbb{R}^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 11\n",
    "\n",
    "Permutation matrices. A square matrix A is called a permutation matrix if it satisfies the following three properties:\n",
    "\n",
    "- all elements of A are either zero or one\n",
    "- each column of A contains exactly one element equal to one\n",
    "- each row of A contains exactly one element equal to one.\n",
    "\n",
    "The matrices\n",
    "\n",
    "$$A_1 = \\begin{bmatrix}\n",
    "0 & 1 & 0\\\\\n",
    "0 & 0 & 1 \\\\\n",
    "1& 0 & 0 \n",
    "\\end{bmatrix}, \\quad\n",
    "A_2 = \\begin{bmatrix}\n",
    "0 & 1 & 0 & 0\\\\\n",
    "0 & 0 & 0 & 1\\\\\n",
    "0 & 0& 1 & 0 \\\\\n",
    "1 & 0 & 0 & 0\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "are examples of permutation matrices. A less formal definition is the following: a permutation matrix is the identity matrix with its rows reordered.\n",
    "\n",
    "(a) Let A be an $n \\times n$ permutation matrix. Give a simple description in words of the relation between a n-vector $x$ and $f(x) = Ax$.\n",
    "\n",
    "(b) Prove that columns of permutation matrix is orthogonal.\n",
    "\n",
    "(c) We can also define a second linear function $g(x) = A^Tx$ in terms of the same permutation matrix. What is the relation between $g$ and $f$ ?\n",
    "\n",
    "Hint: Use the result of (b)\n",
    "\n",
    "(d) Describe meaning of columns and rows of permutation matrix. Then, explain the result of (c)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 2\n",
    "\n",
    "The regularized least-squares problem has the form\n",
    "\n",
    "<br>\n",
    "$$ \\min_{\\theta} \\;\\lVert A\\theta -y\\rVert_2^2 + \\lambda \\lVert \\theta \\rVert_2^2$$\n",
    "\n",
    "(a) Show that the solution is given by\n",
    "<br><br>\n",
    "$$ \\hat{\\theta} = \\left( A^T A + \\lambda I_n \\right)^{-1} A^T y $$\n",
    " (Do not use the method of Lagrangian multipliers)\n",
    "<br><br>\n",
    "\n",
    "(b) Write down a gradient descent algorithm for given optimization problem.\n",
    "\n",
    "(c) Based on the result of (b), describe the role of regularizer term.\n",
    "\n",
    "(d) Describe results of (a) and (b) have the same meaning.\n",
    "\n",
    "(e) Find and draw an approximated curve of the given data points in Python using your gradient descent algorithm.\n",
    "    - overcome overfitting \n",
    "    - use RBF \n",
    "    - choose a proper value of $\\lambda$ on your own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 4. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New problem\n",
    "\n",
    "a) Let's say $x_i$'s are features. We say feature $x_j$ is useless when $P(y|x_1, ... x_{j-1}, x_j, x_j, ... x_N) = P(y|x_1, ... x_{j-1}, x_j, ... x_N)$. Describe the reason.\n",
    "\n",
    "b) In our class, we learn that we can select meaningful feature using Lasso. Describe why Lasso select meaningful feature using above equation.\n",
    "\n",
    "c) Load 'data_input.pkl' and 'data_target.pkl'. Using these, build the classifier using Lasso.\n",
    "\n",
    "d) After applying Lasso, we can select meaningful features. Then, we again apply Lasso to refine our features. Such techniques are called recursive feature elimination. Write the code that recursively apply Lasso to select features and plot the number of features selected at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "X, y = boston.data, boston.target\n",
    "\n",
    "from six.moves import cPickle\n",
    "cPickle.dump(X, open('./data_input.pkl', 'wb'))\n",
    "cPickle.dump(y, open('./data_target.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New problem\n",
    "(a) The figure shows loss functions of each classifier that you have learned in class.\n",
    "\n",
    "<img src=\"./image_files/hinge_.jpg\", width = 500>\n",
    "<center>Figure 1</center>\n",
    "\n",
    "Observe that the hinge loss function does not impose any loss when the inner product between target and prediction is greater than 1. Actually, support vector machine can be coded by setting classifier's loss to the hinge loss function. Describe the reason using the concept of maximum margin.\n",
    "\n",
    "(b) Using the figure, describe why support vector machine is robust to outlier.\n",
    "\n",
    "(c) Write the code that optimizing hinge loss function to build a classifier. Then plot the decision boundary of your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nc7ajjkcJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa9c7b4f518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = load_iris()\n",
    "x, y = iris.data, iris.target\n",
    "x = x[y != 2]\n",
    "y = y[y != 2]\n",
    "y[y == 0] = -1\n",
    "x = x[:,:2]\n",
    "\n",
    "plt.plot(x[y == -1,0], x[y == -1,1], '.')\n",
    "plt.plot(x[y == 1,0], x[y == 1,1], '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 5. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem 1\n",
    "\n",
    "You will use K-means to compress an image by reducing the number of colors it contains.\n",
    "\n",
    "1) Image Representation\n",
    "\n",
    "The data for this exercise contains a 128-pixel by 128-pixel TIFF image named \"bird.tiff.\" It looks like the picture in Figure 1.\n",
    "<br><br>\n",
    "<img src=\"./image_files/clus01.bmp\", width = 250>\n",
    "<br><br>\n",
    "In a straightforward 24-bit color representation of this image, each pixel is represented as three 8-bit numbers (ranging from 0 to 255) that specify red, green and blue (RGB) intensity values. Our bird photo contains thousands of colors, but we'd like to reduce that number to 16. By making this reduction, it would be possible to represent the photo in a more efficient way by storing only the RGB values of the 16 colors present in the image.\n",
    "\n",
    "In this problem, you will use K-means to reduce the color count to $k = 16$. That is, you will compute 16 colors as the cluster centroids and replace each pixel in the image with its nearest cluster centroid color.\n",
    "\n",
    "2) K-means in Matlab\n",
    "\n",
    "<a href = \"https://www.dropbox.com/s/tibygtcahpw9hmk/bird.tiff?dl=0\"> download bird.tiff </a>\n",
    "\n",
    "In Matlab, load the image into your program with the following command:\n",
    "\n",
    "```octave \n",
    "im = imread('bird.tiff');\n",
    "A = double(im);\n",
    "imshow(im)\n",
    "```\n",
    "This creates a three-dimensional matrix $A$ whose first two indices identify a pixel position and whose last index represents red, green, or blue. For example, $A(50, 33, 3)$ gives you the blue intensity of the pixel at position $y = 50, x = 33$. (The y-position is given first, but this does not matter so much in our example because the $x$ and $y$ dimensions have the same size).\n",
    "\n",
    "Your task is to compute 16 cluster centroids from this image, with each centroid being a vector of length three that holds a set of RGB values. Here is the K-means algorithm as it applies to this problem:\n",
    "\n",
    "3) K-means algorithm\n",
    "\n",
    "> 1. For initialization, sample 16 colors randomly from the original picture. There are your \n",
    "$k$ means $\\mu_1, \\mu_2, \\cdots, \\mu_k$.\n",
    "<br><br>\n",
    "> 2. Go through each pixel in the small image and calculate its nearest mean.\n",
    " <br><br>\n",
    " $$c^{(i)} = \\text{arg} min_j \\lVert x^{(i)}-\\mu_j \\rVert^2$$\n",
    " <br><br>\n",
    "> 3. Update the values of the means based on the pixels assigned to them. \n",
    "<br><br>\n",
    "$$\\mu_j = \\frac{\\sum\\limits_i^m 1\\{c^{(i)} = j\\}x^{(i)}}{\\sum\\limits_i^m 1\\{c^{(i)} = j\\}}$$\n",
    "<br><br>\n",
    ">4. Repeat steps 2 and 3 until convergence. This should take between 30 and 100 iterations. You can either run the loop for a preset maximum number of iterations, or you can decide to terminate the loop when the locations of the means are no longer changing by a significant amount.\n",
    "\n",
    "Note: In Step 3, you should update a mean only if there are pixels assigned to it. Otherwise, you will see a divide-by-zero error. For example, it's possible that during initialization, two of the means will be initialized to the same color (_i.e._ black). Depending on your implementation, all of the pixels in the photo that are closest to that color may get assigned to one of the means, leaving the other mean with no assigned pixels.\n",
    "\n",
    "When you have recalculated the image, you can display it. When you are finished, compare your image to the one in the solutions.\n",
    "\n",
    "```octave\n",
    "imshow(unit8(A16));\n",
    "```\n",
    "\n",
    "<img src=\"./image_files/clus02.bmp\", width = 250>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

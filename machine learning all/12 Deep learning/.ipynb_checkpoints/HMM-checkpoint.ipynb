{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size = '6'><b>Hidden Markov Model</b></font>\n",
    "<br>\n",
    "\n",
    "- <a href=\"./files/hmm14a.pdf\" target=\"_blank\">HMM Slides</a> from Prof. Andrew W. Moore at CMU<br>\n",
    "- <a href=\"./files/Lecture17.pdf\" target=\"_blank\">HMM Slides</a> from Prof. AartiSingh at CMU<br>\n",
    "- <a href=\"./files/HMM Tutorial.pdf\" target=\"_blank\">HMM tutorial paper</a> from Lawrence R. Rabiner\n",
    "\n",
    "<table style=\"border-style: hidden; border-collapse: collapse;\" width = \"90%\"> \n",
    "    <tr style=\"border-style: hidden; border-collapse: collapse;\">\n",
    "        <td width = 60% style=\"border-style: hidden; border-collapse: collapse;\">\n",
    "             \n",
    "        </td>\n",
    "        <td width = 30%>\n",
    "        Prof. Seungchul Lee<br>\n",
    "        iSystems Design Lab<br>UNIST<br>http://isystems.unist.ac.kr/\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "Table of Contents\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Markov Process\n",
    "\n",
    "## 1.1. Sequential Data\n",
    "\n",
    "- Most classifiers ignored the sequential aspects of data\n",
    "\n",
    "- Consider a system which can occupy one of $N$ discrete states or categories\n",
    "\n",
    "$$q_t \\in \\{S_1, S_2, \\cdots S_N\\}$$\n",
    "\n",
    "- We are interested in stochastic systems, in which state evolution is random\n",
    "\n",
    "- Any joint distribution can be factored into a series of conditional distributions\n",
    "\n",
    "$$ p(q_0,q_1,\\cdots,q_T) = p(q_0)\\,p(q_1 \\mid q_0) \\, p(q_2 \\mid q_1,q_0)\\cdots$$\n",
    "\n",
    "- But almost impossible to compute !!!\n",
    "\n",
    "## 1.2. Hidden Markov Process\n",
    "\n",
    "__Markov chain__\n",
    "\n",
    "- For a Markov process, the next state depends only on the current state:\n",
    "\n",
    "$$ p(q_{t+1} \\mid q_t,\\cdots,q_0) = p(q_{t+1} \\mid q_t)$$\n",
    "\n",
    "- More clearly\n",
    "\n",
    "$$ p(q_{t+1} = s_j \\mid q_t = s_i) = p(q_{t+1} = s_j \\mid q_t = s_i, \\text{ any earlier history}) $$\n",
    "\n",
    "\\begin{align*}\n",
    " p(q_0,q_1,\\cdots,q_T) &= p(q_0)\\,p(q_1 \\mid q_0) \\, p(q_2 \\mid q_1,q_0) \\, p(q_3 \\mid q_2,q_1,q_0)\\cdots\\\\\n",
    "&= p(q_0)\\,p(q_1 \\mid q_0)\\,p(q_2 \\mid q_1)\\,p(q_3 \\mid q_2)\\cdots\n",
    "\\end{align*}\n",
    "\n",
    "- Now it is a kind of poosible and tractable in computation\n",
    "\n",
    "<img src=\"./image_files/mc.png\" width = 250>\n",
    "\n",
    "__State Transition Matrix__\n",
    "\n",
    "- A stationary Markov chain with $N$ states is described by an $N \\times N$ transition matrix\n",
    "\n",
    "$$ \n",
    "\\begin{bmatrix}\n",
    "a_{11} & a_{12} & a_{13}\\\\a_{21} & a_{22} & a_{23}\\\\a_{31} & a_{32} & a_{33} \n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "0 & 0 & 1 \\\\ 1/2 & 1/2 & 0 \\\\ 1/3 & 2/3 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "__ Hidden State__\n",
    "\n",
    "- Assumption\n",
    "    - We can observe something that is affected by the true state\n",
    "    - Natual way of thinking\n",
    "\n",
    "- Limited sensors (incomplete state information)\n",
    "    - But still partially related\n",
    "    \n",
    "- Noisy senors\n",
    "    - Unreliable\n",
    "    \n",
    "- Observation emitted from $q_t$\n",
    "    - $O_t$ is noisily determined, depending on the current state $q_t$\n",
    "    - Assume that $O_t$ is conditionally independent of $\\{q_{t-1},q_{t-2},\\cdots,q_0,O_{t-1},O_{t-2},\\cdots,O_0 \\}$ given $q_t$\n",
    "\n",
    "__Markov Property__\n",
    "\n",
    "1. a finite set of $N$ states, $S=\\{S_1,\\cdots S_N\\}$\n",
    "\n",
    "2. a state transition probability, $ P= \\{ a_{ij} \\}_{N\\times N}, \\; i \\leq i,j \\leq N $\n",
    "\n",
    "3. an initial state probability distribution, $\\pi = \\{\\pi_i\\}$\n",
    "\n",
    "4. an observation symbol probability distribution, $b_j(O_n)$\n",
    "\n",
    "<br>\n",
    "<img src=\"./image_files/hmm.png\" width = 400>\n",
    "<center>very simplified HMM</center>\n",
    "\n",
    "## 1.3. Three Questions in HMM \n",
    "\n",
    "- Question 1: State estimation (most interesting to us)\n",
    "\n",
    "$\\qquad$ What is $p(q_t = s_i \\mid O_1,O_2,\\cdots,O_T)$\n",
    "\n",
    "- Question 2: Most probable path\n",
    "\n",
    "$\\qquad$ Given $O_1 O_2 \\cdots O_T$, what is the most probable path that I took? And what is that probability?\n",
    "\n",
    "- Question 3: Learning HMMs\n",
    "\n",
    "$\\qquad$ Given $O_1 O_2 \\cdots O_T$, what is the maximum likelihood HMM that could have produced this sequence of observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. State Estimation\n",
    "\n",
    "Given the observation sequence $O = O_1 O_2 \\cdots O_T$, the probability of $q_T = S_i$\n",
    "\n",
    "$$p(q_T = S_i \\mid O_1 O_2 \\cdots O_T, \\lambda)$$\n",
    "\n",
    "Then estiamted state $\\hat{q}_T$\n",
    "\n",
    "$$ \\hat{q}_T = \\arg \\max_{i} \\{ p(q_T = S_i \\mid O_1 O_2 \\cdots O_T, \\lambda) \\} $$\n",
    "\n",
    "\n",
    "<br>\n",
    "Bayes' rule with conditional probabiliy\n",
    "\n",
    "\\begin{align*}\n",
    "p(A,B \\mid C) &= p(A \\mid B,C)\\,p(B \\mid C)\\\\\n",
    "\\implies p(A \\mid B,C) &= \\frac{p(A,B \\mid C)}{p(B \\mid C)}\n",
    "\\end{align*}\n",
    "\n",
    "- $A: q_T = S_i$\n",
    "\n",
    "- $B: O_1 O_2 \\cdots O_T$\n",
    "\n",
    "- $C: \\lambda$\n",
    "\n",
    "$$p(q_T = S_i \\mid O_1 O_2 \\cdots O_T, \\lambda) = \\frac{p(q_T = S_i , O_1 O_2 \\cdots O_T \\mid \\lambda)}{p(O_1 O_2 \\cdots O_T \\mid \\lambda)}$$\n",
    "\n",
    "__Start with wrong approach__\n",
    "\n",
    "HMM: $\\lambda$\n",
    "\n",
    "For one fixted state sequence $q = q_1 q_2 \\cdots q_T$\n",
    "\n",
    "\\begin{align*}\n",
    "p(O \\mid q,\\lambda) &= \\prod_{t=1}^{T} p(O_t \\mid q_t, \\lambda)\\\\\n",
    "&= b_{q_1}(O_1)\\cdots b_{q_T}(O_T)\n",
    "\\end{align*}\n",
    "\n",
    "Probability of such a sate sequence $q$\n",
    "\n",
    "$$ p(q \\mid \\lambda) = \\pi_{q_1} a_{q_1 a_2} a_{q_2 a_3} \\cdots a_{q_{T-1} a_T}$$\n",
    "\n",
    "Then\n",
    "\\begin{align*}\n",
    "p(O \\mid \\lambda) &= \\sum_{\\text{all } q} p(O,q \\mid \\lambda)\\\\\n",
    "&= \\sum_{\\text{all }q}p(O \\mid q, \\lambda)p(q \\mid \\lambda)\n",
    "\\end{align*}\n",
    "\n",
    "$\\rightarrow$ require too much computation\n",
    "\n",
    "__Smarter way__\n",
    "\n",
    "$$p(q_T = S_i \\mid O_1 O_2 \\cdots O_T, \\lambda) = \\frac{p(q_T = S_i , O_1 O_2 \\cdots O_T \\mid \\lambda)}{p(O_1 O_2 \\cdots O_T \\mid \\lambda)}$$\n",
    "\n",
    "Let \n",
    "\n",
    "$$\\alpha_t(i) \\equiv p(O_1 O_2 \\cdots O_t, q_t = S_i \\mid \\lambda) $$\n",
    "\n",
    "Then\n",
    "\n",
    "\\begin{align*}\n",
    "\\alpha_1(i) &= p(O_1, q_1 = S_i \\mid \\lambda) = \\pi_i b_i(O_1)\\\\\n",
    "&\\; \\vdots \\\\\n",
    "\\alpha_t(i) &= p(O_1 O_2 \\cdots O_t, q_t = S_i \\mid \\lambda)\\\\\n",
    "\\alpha_{t+1}(j) &= p(O_1 O_2 \\cdots O_{t+1}, q_{t+1} = S_j \\mid \\lambda)\\\\\n",
    "&= \\left( \\sum_{i=1}^{N} \\alpha_t(i) a_{ij} \\right) b_j(O_{t+1} ) \\\\\n",
    "&\\; \\vdots \\\\\n",
    "\\alpha_T(j) &= p(O_1 O_2 \\cdots O_T, q_T = S_j \\mid \\lambda) \\quad \\text{: recursive}\n",
    "\\end{align*}\n",
    "\n",
    "Back to the problem\n",
    "\n",
    "$$ p(O_1 O_2 \\cdots O_T \\mid \\lambda) = p(O \\mid \\lambda) = \\sum_{j=1}^{N} \\alpha_T(j) $$\n",
    "\n",
    "$$p(q_T = S_i \\mid O_1 O_2 \\cdots O_T, \\lambda) = \\frac{p(q_T = S_i , O_1 O_2 \\cdots O_T \\mid \\lambda)}{p(O_1 O_2 \\cdots O_T \\mid \\lambda)} = \\frac{\\alpha_T(i)}{\\sum_{j=1}^{N}\\alpha_T(j)}$$\n",
    "\n",
    "Then estimated state $\\hat{q}_T$\n",
    "\n",
    "$$ \\hat{q}_T = \\arg \\max_{i} \\left\\{ p(q_T = S_i \\mid O_1 O_2 \\cdots O_T, \\lambda) \\right\\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__Some thouhgts on HMM__\n",
    "\n",
    "- Sequence information\n",
    "    - comes from state transition matrix\n",
    "    - difficult to obtain it in practice\n",
    "    - sequence might be useful in some applications\n",
    "\n",
    "- Not easy to obtain observation symbol probability $b_j(O_n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='5'><b>Online lectures</b></font>\n",
    "\n",
    "- Lucy Yin at Caltech (https://www.youtube.com/watch?v=NebQx50u9gw)\n",
    "\n",
    "- Bert Huang at Virginia Tech (https://www.youtube.com/watch?v=9yl4XGp5OEg)\n",
    "\n",
    "- Nando de Freitas at UBC (https://www.youtube.com/watch?v=jY2E6ExLxaw)\n",
    "\n",
    "- By mathematicalmonk (https://www.youtube.com/watch?v=TPRoLreU9lA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

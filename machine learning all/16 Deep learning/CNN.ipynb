{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<font size = '6'><b>Convolution Neural Networks</b></font>\n",
    "\n",
    "- <a href=\"./reference_files/deep_learning_tutorial_2015.pdf\" target=\"_blank\">Slides</a> by Phillip Isola\n",
    "- <a href=\"./reference_files/cnn1.pdf\" target=\"_blank\">Slides</a> by Prof. Ali Ghodsi\n",
    "\n",
    "<table style=\"border-style: hidden; border-collapse: collapse;\" width = \"90%\"> \n",
    "    <tr style=\"border-style: hidden; border-collapse: collapse;\">\n",
    "        <td width = 60% style=\"border-style: hidden; border-collapse: collapse;\">\n",
    "             \n",
    "        </td>\n",
    "        <td width = 30%>\n",
    "        Prof. Seungchul Lee<br>\n",
    "        iSystems<br>\n",
    "        UNIST<br>\n",
    "        http://isystems.unist.ac.kr/\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Table of Contents\n",
    "<div id=\"toc\"></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tranditional Machine Learning vs. Neural Networks\n",
    "\n",
    "__Object recognition using machine learning__\n",
    "\n",
    "<img src=\"./image_files/ML_clown_fish.png\" width = 500>\n",
    "\n",
    "__Neural Network__\n",
    "\n",
    "<table style=\"border-style: hidden; border-collapse: collapse;\" width = \"96%\"> \n",
    "    <tr style=\"border-style: hidden; border-collapse: collapse;\">\n",
    "        <td width = 48% style=\"border-style: hidden; border-collapse: collapse;\">\n",
    "<img src=\"./image_files/nn_clown_fish.png\" width = 350>\n",
    "        </td>\n",
    "        <td width = 48%>\n",
    "<img src=\"./image_files/nn_fish.png\" width = 350>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "___Deep_ Neural Network__\n",
    "\n",
    "<img src=\"./image_files/deep_fish.png\" width = 500>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Convolution Neural Networks\n",
    "\n",
    "CNNs are simply neural networks that use _convolution_ in place of general matrix multiplication in at least one of their layers\n",
    "\n",
    "## 2.1. Convolution and cross-correlation\n",
    "\n",
    "- Many machine learning libraries implement cross-correlation, but call it convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.youtube.com/embed/Ma0YONjMZLI\" \n",
       "width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"https://www.youtube.com/embed/Ma0YONjMZLI\" \n",
    "width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Discrete convolution can be viewed as multiplication by a matrix\n",
    "\n",
    "<img src=\"./image_files/conv_animation.gif\" width = 400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"border-style: hidden; border-collapse: collapse;\" width = \"96%\"> \n",
    "    <tr style=\"border-style: hidden; border-collapse: collapse;\">\n",
    "        <td width = 48% style=\"border-style: hidden; border-collapse: collapse;\">\n",
    "<img src=\"./image_files/conv.png\" width = 400>\n",
    "        </td>\n",
    "        <td width = 48%>\n",
    "<img src=\"./image_files/cnn_conv.png\" width = 400>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "__Sparse interations__\n",
    "\n",
    "- CNNs, typically have sparse connectivity (sparse weights)\n",
    "\n",
    "- This is accomplished by making the kernel (convolution mask) smaller than the input\n",
    " \n",
    "\n",
    "__Parameter sharing__\n",
    "\n",
    "- In CNNs each number of the kernel is used at every position of the input\n",
    "\n",
    "- Instead of learning a separate set of parameters for every location, we learn only one set\n",
    "\n",
    "\n",
    "__Equivariance__\n",
    "\n",
    "- A function $f(x)$ is equivariant to a function $g$ if $f(g(x)) = g(f(x))$\n",
    "\n",
    "- A convolution layer has equivariance to translation\n",
    "\n",
    "- If we apply this translation to $x$, then apply convolution, the result will be the same as if we applied convolution to $x$, then applied the transformation to the output\n",
    "\n",
    "- Note that convolution is not equivariant to some other transformation, such as changes in the scale or rotation of an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Computation in a neural net\n",
    "\n",
    "__1) Linear combination__\n",
    "\n",
    "<img src=\"./image_files/linear_sum.png\" width = 320>\n",
    "\n",
    "__2) Nonlinear activation function__\n",
    "\n",
    "<img src=\"./image_files/ReLU.png\" width = 500>\n",
    "\n",
    "\n",
    "__3) Pooling functions__\n",
    "\n",
    "<img src=\"./image_files/max_pool.png\" width = 400>\n",
    "\n",
    "- The maximum of a rectangular neighborhood (max pooling operation)\n",
    "\n",
    "<img src=\"./image_files/max_pooling.png\" width = 300>\n",
    "\n",
    "- Other candiates\n",
    "    - the average of a rectangular neighborhood\n",
    "    - the $L_2$ norm of a rectangular neighborhood\n",
    "\n",
    "\n",
    "- Pooling with downsampling\n",
    "    - reduce the representation size by a factor of 2, which reduces the computational and statistical burden on the next layer\n",
    "\n",
    "<img src=\"./image_files/pooling_downsampling.png\" width = 400>\n",
    "\n",
    "- Pooling and translations\n",
    "    - Pooling helps to make the representation become invariant to small translations of the input\n",
    "<img src=\"./image_files/pooling_translation.png\" width = 500>\n",
    "    - Invariance to local translation can be a very useful property if we care more about whether some feature is present than exactly where it is.\n",
    "\n",
    "    - For example, we need not know the exact location of the eyes in a face\n",
    "\n",
    "<img src=\"./image_files/pool_edge.png\" width = 500>\n",
    "\n",
    "__4) Classification__\n",
    "\n",
    "<img src=\"./image_files/classification.png\" width = 450>\n",
    "\n",
    "__CNN summary__\n",
    "\n",
    "<table style=\"border-style: hidden; border-collapse: collapse;\" width = \"96%\"> \n",
    "    <tr style=\"border-style: hidden; border-collapse: collapse;\">\n",
    "        <td width = 48% style=\"border-style: hidden; border-collapse: collapse;\">\n",
    "<img src=\"./image_files/layer_of_cnn.png\" width = 450>\n",
    "        </td>\n",
    "        <td width = 48%>\n",
    "<img src=\"./image_files/cnn.png\" width = 400>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Ingredients\n",
    "\n",
    "- Select important features of the data\n",
    "    - linear filters\n",
    "    - pointwise nonlinearity\n",
    "\n",
    "\n",
    "- Group features that all indicate the same thing\n",
    "    - pooling\n",
    "\n",
    "\n",
    "- Repeat to achieve greater abstraction\n",
    "\n",
    "<img src=\"./image_files/cnn_ideas.png\" width = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Learning\n",
    "\n",
    "- Backpropagation and \n",
    "\n",
    "- stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. How to avoid overfitting?\n",
    "\n",
    "- Convolutional nets use a prior that stuff in the world does not change identity as it translates\n",
    "\n",
    "- Data Augmentation\n",
    "    - Augment the training data by adding jittered versions of each image\n",
    "\n",
    "<img src=\"./image_files/data_aug.png\" width = 500>\n",
    "\n",
    "- Dropout\n",
    "    - Randomly choose edges not to update\n",
    "    - Insensitive to local changes\n",
    "    - acting as regularization\n",
    "    \n",
    "<img src=\"./image_files/dropout.png\" width = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. How do deep neural nets work?\n",
    "\n",
    "- Hierarchy of simple, repeated computations\n",
    "\n",
    "- Sift through data by filtering it\n",
    "\n",
    "- Build up invariance by pooling alike features\n",
    "\n",
    "- Can be learned with vanilla SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Software Tools\n",
    "\n",
    "- Caffe\n",
    "    - fast and popular\n",
    "    - hard to use\n",
    "    - C++ with linited Matlab and Python interfaces\n",
    "\n",
    "- Theano\n",
    "    - Symbolic computation and automatic differentiation python\n",
    "\n",
    "- Torch\n",
    "    - Lua\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='5'><b>Online Video Lectures</b></font>\n",
    "\n",
    "- <a href=\"./reference_files/deep_learning_tutorial_2015.pdf\" target=\"_blank\">Slides</a> by Phillip Isola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.youtube.com/embed/bL1Zymz1b7g\" \n",
       "width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"https://www.youtube.com/embed/bL1Zymz1b7g\" \n",
    "width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <a href=\"./reference_files/cnn1.pdf\" target=\"_blank\">Slides</a> by Prof. Ali Ghodsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.youtube.com/embed/ZMBp7_qqtLE\" \n",
       "width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"https://www.youtube.com/embed/ZMBp7_qqtLE\" \n",
    "width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

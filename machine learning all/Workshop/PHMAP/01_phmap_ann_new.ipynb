{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<font size='6'><b>Artificial Neural Networks (ANN)\n",
    "</b></font></br></br>\n",
    "\n",
    "<table style=\"border-style: hidden; border-collapse: collapse;\" width = \"80%\"> \n",
    "    <tr style=\"border-style: hidden; border-collapse: collapse;\">\n",
    "        <td width = 55% style=\"border-style: hidden; border-collapse: collapse;\">\n",
    "\n",
    "        </td>\n",
    "        <td width = 25%>\n",
    "        By Prof. Seungchul Lee<br>iSystems Design Lab<br>http://isystems.unist.ac.kr/<br>UNIST\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "</table>\n",
    "\n",
    "Table of Contents\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Deep Learning Libraries\n",
    "\n",
    "__Caffe__\n",
    "\n",
    "<img src=\"./image_files/Caffe_logo.png\" width = 200>\n",
    "\n",
    "- Platform: Linux, Mac OS, Windows\n",
    "- Written in: C++\n",
    "- Interface: Python, MATLAB\n",
    "\n",
    "<br>\n",
    "__Theano__\n",
    "<img src=\"./image_files/Theano_logo.png\" width = 200>\n",
    "\n",
    "- Platform: Cross-platform\n",
    "- Written in: Python\n",
    "- Interface: Python\n",
    "\n",
    "<br>\n",
    "__Tensorflow__\n",
    "\n",
    "<img src=\"./image_files/Tensorflow_logo.png\" width = 250>\n",
    "\n",
    "- Platform: Linux, Mac OS, Windows\n",
    "- Written in: C++, Python\n",
    "- Interface: Python, C/C++, Java, Go, R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Machine Learning and Deep Learning\n",
    "\n",
    "__Machine Learning__\n",
    "- Hand-crafted features\n",
    "- Depends on expertise\n",
    "    \n",
    "__Deep Learning__\n",
    "- Automatic feature extraction\n",
    "- Depends on network structure\n",
    "\n",
    "<img src=\"./image_files/ML_DL.PNG\" width = 700>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Artificial Neural Networks\n",
    "\n",
    "__= Multi Layer Perceptrons (MLPs)__\n",
    "\n",
    "__Transformation__\n",
    "- Affine (or linear) transformation and nonlinear activation (layer)\n",
    "\n",
    "$$ f(x) = g\\left(\\theta^{T}x + b\\right) $$\n",
    "\n",
    "- Nonlinear activation function\n",
    "\n",
    "<table style=\"border-style: hidden; border-collapse: collapse;\" width = \"96%\"> \n",
    "    <tr style=\"border-style: hidden; border-collapse: collapse;\">\n",
    "        <td width = 28% style=\"border-style: hidden; border-collapse: collapse;\">\n",
    "            <img src=\"./image_files/sigmoid_function.jpg\" width = 250>\n",
    "            $$ g(x) = \\frac{1}{1+e^{-x}}$$\n",
    "        </td>\n",
    "        <td width = 28% style=\"border-style: hidden; border-collapse: collapse;\">\n",
    "            <img src=\"./image_files/tanh_function.jpg\" width = 250>\n",
    "            <br>\n",
    "            $$ g(x) = \\tanh (x)$$\n",
    "        </td>\n",
    "        <td width = 28% style=\"border-style: hidden; border-collapse: collapse;\">\n",
    "            <img src=\"./image_files/relu_function.jpg\" width = 250>\n",
    "            <br>\n",
    "            $$ g(x) = \\max (0, x)$$\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<br>\n",
    "__Deep Network__\n",
    " - Apply multiple layers \n",
    "$$  f(x) = f^{(3)}(f^{(2)}(f^{(1)}(x))) $$\n",
    "\n",
    "- $ z = f^{(1)}(x) $ is called a hidden layer\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"./image_files/deep_structure.png\" width = 450>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loss Function__\n",
    "\n",
    "- Measures error between target values and predictions\n",
    "- More or less the same as those for other parametric models, such as linear models\n",
    "\n",
    "$$ \\min_{\\theta} \\sum_{i=1}^{m}\\ell\\left( h_{\\theta}\\left(x^{(i)}\\right),y^{(i)}\\right)$$\n",
    "\n",
    "- Example\n",
    "    - Cross entropy:\n",
    "    $$ -\\frac{1}{N}\\sum_{i=1}^{N}y^{(i)}\\log(h_{\\theta}\\left(x^{(i)}\\right)) + (1-y^{(i)})\\log(1-h_{\\theta}\\left(x^{(i)}\\right))$$\n",
    "    - Squared loss:\n",
    "    $$  \\frac{1}{N} \\sum_{i=1}^{N} (h_{\\theta}\\left(x^{(i)}\\right) - y^{(i)})^2 $$\n",
    "\n",
    "__Backpropagation__\n",
    "\n",
    "- Forward propagation \n",
    "    - the initial information propagates up to the hidden units at each layer and finally produces output\n",
    "- Backpropagation\n",
    "    - allows the information from the cost to flow backwards through the network in order to compute the gradients\n",
    "\n",
    "<img src=\"./image_files/animate_backpropa.gif\" width = 450>\n",
    "\n",
    "__(Stochastic) Gradient Descent__\n",
    "\n",
    "- Negative gradients points directly downhill of cost function\n",
    "- We can decrease cost by moving in the direction of the negative gradient ($\\alpha$ is a learning rate)\n",
    "\n",
    "$$ \\theta:= \\theta - \\alpha \\nabla_{\\theta} \\left( h_{\\theta} \\left(x^{(i)}\\right),y^{(i)}\\right)$$\n",
    "\n",
    "<table style=\"border-style: hidden; border-collapse: collapse;\" width = \"96%\"> \n",
    "    <tr style=\"border-style: hidden; border-collapse: collapse;\">\n",
    "        <td width = 48% style=\"border-style: hidden; border-collapse: collapse;\">\n",
    "            <img src=\"./image_files/GradientDescent.png\" width = 450>\n",
    "        </td>\n",
    "        <td width = 48% style=\"border-style: hidden; border-collapse: collapse;\">\n",
    "            <img src=\"./image_files/GradientDescent_3d.png\" width = 450>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ANN with TensorFlow\n",
    "\n",
    "- MNIST (Mixed National Institute of Standards and Technology database) database\n",
    "    - Handwritten digit database\n",
    "    - $28 \\times 28$ gray scaled image\n",
    "    - Flattened array into a vector of $28 \\times 28 = 784$\n",
    "    \n",
    "<img src=\"./image_files/mnist_digits.png\" width = 450>\n",
    "\n",
    "<img src=\"./image_files/MNIST-Matrix.png\" width = 450>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"./image_files/MNIST_neuralnet_image.png\" width = 500>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center><iframe src=\"https://www.youtube.com/embed/z0bynQjEpII?start=2088&end=3137\" \n",
       "width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen></iframe></center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<center><iframe src=\"https://www.youtube.com/embed/z0bynQjEpII?start=2088&end=3137\" \n",
    "width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen></iframe></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Load MNIST Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download MNIST data from tensorflow tutorial example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MINST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MINST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MINST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MINST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MINST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALgAAADECAYAAAAs0+t9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe12f9507b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_x, train_y = mnist.train.next_batch(10)\n",
    "img = train_x[3,:].reshape(28,28)\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.imshow(img,'gray')\n",
    "plt.title(\"Label : {}\".format(np.argmax(train_y[3])))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels : [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print ('Train labels : {}'.format(train_y[3, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Build a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ First, the layer performs several matrix multiplication to produce a set of linear activations __\n",
    "\n",
    "<img src=\"./image_files/linear_sum2.png\" width = 320>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y_j = \\left(\\sum\\limits_i \\omega_{ij}x_i\\right) + b_j$$\n",
    "\n",
    "$$\\mathcal{y} = \\mathcal{w}^T \\mathcal{x} + \\mathcal{b}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "# hidden1 = tf.matmul(x, weights['hidden1']) + biases['hidden1']\n",
    "hidden1 = tf.add(tf.matmul(x, weights['hidden1']), biases['hidden1'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Second, each linear activation is running through a nonlinear activation function __\n",
    "\n",
    "<img src=\"./image_files/ReLU.png\" width = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "hidden1 = tf.nn.relu(hidden1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Third, predict values with affine transformation__\n",
    "\n",
    "<img src=\"./image_files/classification.png\" width = 450>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "# output = tf.matmul(hidden1, weights['output']) + biases['output']\n",
    "output = tf.add(tf.matmul(hidden1, weights['output']), biases['output'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Define an ANN Shape\n",
    "\n",
    "- Input size\n",
    "- Hidden layer size\n",
    "- The number of classes\n",
    "\n",
    "<img src=\"./image_files/MNIST_neuralnet_image.png\" width = 500>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 28*28\n",
    "n_hidden1 = 100\n",
    "n_output = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. Define Weights, Biases and Network\n",
    "- Define parameters based on predefined layer size\n",
    "- Initialize with normal distribution with $\\mu = 0$ and $\\sigma = 0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'hidden1' : tf.Variable(tf.random_normal([n_input, n_hidden1], stddev = 0.1)),\n",
    "    'output' : tf.Variable(tf.random_normal([n_hidden1, n_output], stddev = 0.1)),\n",
    "}\n",
    "biases = {\n",
    "    'hidden1' : tf.Variable(tf.random_normal([n_hidden1], stddev = 0.1)),\n",
    "    'output' : tf.Variable(tf.random_normal([n_output], stddev = 0.1)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Network\n",
    "def net(x, weights, biases):\n",
    "    # first hidden layer\n",
    "    hidden1 = tf.add(tf.matmul(x, weights['hidden1']), biases['hidden1'])\n",
    "    # non linear activate function\n",
    "    hidden1 = tf.nn.relu(hidden1)\n",
    "    \n",
    "    # Output layer with linear activation\n",
    "    output = tf.add(tf.matmul(hidden1, weights['output']), biases['output'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6. Define Cost, Initializer and Optimizer\n",
    "\n",
    "__Loss__\n",
    "- Classification: Cross entropy\n",
    "    - Equivalent to apply logistic regression\n",
    "$$ -\\frac{1}{N}\\sum_{i=1}^{N = 50}y^{(i)}\\log(h_{\\theta}\\left(x^{(i)}\\right)) + (1-y^{(i)})\\log(1-h_{\\theta}\\left(x^{(i)}\\right)) $$\n",
    "\n",
    "__Initializer__\n",
    "- Initialize all the empty variables\n",
    "    \n",
    "__Optimizer__\n",
    "- AdamOptimizer: The most popular optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Cost\n",
    "LR = 0.0001\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_output])\n",
    "\n",
    "pred = net(x, weights, biases)\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y)\n",
    "loss = tf.reduce_mean(loss)\n",
    "\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "optm = tf.train.AdamOptimizer(LR).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7. Summary of Model\n",
    "\n",
    "<br>\n",
    "<img src=\"./image_files/cnn_summary of model.png\" width = 500>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8. Define Configuration\n",
    "- Define parameters for training ANN\n",
    "     - n_batch : batch size for stochastic gradient descent\n",
    "     - n_iter : the number of training steps\n",
    "     - n_prt : check loss for every n_prt iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_batch = 50     # Batch Size\n",
    "n_iter = 2500    # Training Iteration\n",
    "n_prt = 250      # Print Cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.9. Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter : 0\n",
      "Cost : 2.4248719215393066\n",
      "Iter : 250\n",
      "Cost : 1.430584192276001\n",
      "Iter : 500\n",
      "Cost : 0.8873671293258667\n",
      "Iter : 750\n",
      "Cost : 0.6424514055252075\n",
      "Iter : 1000\n",
      "Cost : 0.43085211515426636\n",
      "Iter : 1250\n",
      "Cost : 0.5054035782814026\n",
      "Iter : 1500\n",
      "Cost : 0.3671915531158447\n",
      "Iter : 1750\n",
      "Cost : 0.4064554274082184\n",
      "Iter : 2000\n",
      "Cost : 0.24371862411499023\n",
      "Iter : 2250\n",
      "Cost : 0.2499776929616928\n"
     ]
    }
   ],
   "source": [
    "# Run initialize\n",
    "config = tf.ConfigProto(allow_soft_placement=True)  # GPU Allocating policy\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(init)\n",
    "\n",
    "# Training cycle\n",
    "for epoch in range(n_iter):\n",
    "    train_x, train_y = mnist.train.next_batch(n_batch)\n",
    "    sess.run(optm, feed_dict={x: train_x,  y: train_y}) \n",
    "    \n",
    "    if epoch % n_prt == 0:\n",
    "        c = sess.run(loss, feed_dict={x: train_x,  y: train_y})\n",
    "        print (\"Iter : {}\".format(epoch))\n",
    "        print (\"Cost : {}\".format(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.10. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 94.0%\n"
     ]
    }
   ],
   "source": [
    "test_x, test_y = mnist.test.next_batch(100)\n",
    "\n",
    "my_pred = sess.run(pred, feed_dict={x : test_x})\n",
    "my_pred = np.argmax(my_pred, axis=1)\n",
    "\n",
    "labels = np.argmax(test_y, axis=1)\n",
    "\n",
    "accr = np.mean(np.equal(my_pred, labels))\n",
    "print(\"Accuracy : {}%\".format(accr*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhUDChUDChUDChUDChUDChUDChUD/AcRuAKgiqOMgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe12cff3c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction : 6\n",
      "Probability : [ 0.01  0.    0.    0.    0.    0.01  0.98  0.    0.    0.  ]\n"
     ]
    }
   ],
   "source": [
    "test_x, test_y = mnist.test.next_batch(1)\n",
    "logits = sess.run(tf.nn.softmax(pred), feed_dict={x : test_x})\n",
    "predict = np.argmax(logits)\n",
    "\n",
    "plt.imshow(test_x.reshape(28,28), 'gray')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "print('Prediction : {}'.format(predict))\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "print('Probability : {}'.format(logits.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

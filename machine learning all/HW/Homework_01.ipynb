{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Prove that any projection matrix $P$ for an orthogonal projection in $\\mathbb{R}^n$ satisfies the two properties:\n",
    "\n",
    "1) $P^2 = P$\n",
    "\n",
    "2) $P$ is symmetric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "Show that the hyperplane $g(X) = \\omega^TX + b = 0$ is perpendicular to $\\omega$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "In this problem, we want to explore a reflection transformation of $X$, which produces a mirror vector $Z$ with respect to vector $V$. See Figure 1.\n",
    "\n",
    "<img src=\"./image_files/problem01.png\", width = 250>\n",
    "<center>Figure 1</center>\n",
    "\n",
    "1) Is a reflection transformation linear?\n",
    "\n",
    "2) If yes, find matrix $M$ such that $Z = MX$\n",
    "\n",
    "3) For $V = \\begin{bmatrix} 1 & 1 \\end{bmatrix}^T$, compute $M$ and its eigenvalues/eigenvectors (here, vector $V$ is a vector with 45 degree angle with x-axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 \n",
    "\n",
    "Projection of a vector $x$ on a given vector $y$. Let y be a given $n$-vector, and consider the function $f : \\mathbb{R}^n \\implies \\mathbb{R}^n$, defined as\n",
    "\n",
    "$$f(x) = \\frac{x^Ty}{\\lVert y\\rVert^2}y$$\n",
    " \n",
    "We know that $f(x)$ is the projection of $x$ on the (fixed, given) vector $y$. Is $f$ a linear function of $x$? If your answer is yes, give an $n^Tn$  matrix $A$ such that $f(x) = Ax$  for all $x$ . If your answer is no, show with an example that $f$ does not satisfy the definition of linearity  $f(\\alpha u + \\beta v) = \\alpha f(u) + \\beta f(v)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "\n",
    "(a) Find the solution by setting the derivatives of the following objective function:\n",
    "\n",
    "$$\\min \\, (2x_1 - 1)^2 + (-x_1 + x_2)^2 + (2x_2 +1)^2$$\n",
    "\n",
    "(b) Formulate the corresponding least-squares problem (i.e., find $A$ and $b$), and solve it using cvx.\n",
    " \n",
    "$$\\min \\, \\lVert Ax - b\\rVert_2$$\n",
    "\n",
    "Hint: it is justified that if $x$ minimizes $\\lVert Ax - b \\rVert^2_2$ , then it also minimize $\\lVert Ax - b\\rVert_2$ .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "\n",
    "Suppose you receive the binary signal. The signal is corrupted with noises while transmitting through channels. We want to estimate original signal through the $L_1$ optimization. The mathematical problem statement is given: \n",
    "\n",
    "$$\n",
    "\\begin{array}{Icr}\\begin{align*}\n",
    "y = x + \\omega\\\\\n",
    "x \\in \\{ 0, 1 \\}\\\\\n",
    "\\omega \\text{ is noise}\n",
    "\\end{align*}\\end{array}\n",
    "\\quad \\Longrightarrow \n",
    "\\begin{array}{I} \\quad \n",
    "\\text{Recover original signal } x \\text{ from corrupted signal } y\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Note: this problem will be revisited after a midterm. We will solve this problem using the probability theory later.\n",
    "\n",
    "### Step 1. Data generation\n",
    "\n",
    "First, let’s generate the original signal as shown in the below figure. This can be simply done using ones and zeros commands in Matlab. \n",
    "\n",
    "<img src=\"./image_files/problem06.png\", width = 400>\n",
    "\n",
    "Next, corrupt the original signal with Gaussian noise. This can be done using randn command in MATLAB. One of realizations of the corrupted signal will be given: \n",
    "\n",
    "<img src=\"./image_files/problem07.png\", width = 400>\n",
    "\n",
    "### Step 2. $L_1$ optimization\n",
    "\n",
    "Note that the signal is sparse (in a sense of frequency domain). Therefore we can apply the $L_1$ optimization. We will optimize the $L_2$ cost function with the $L_1$ constraints. Here’s a rough CVX code : \n",
    "\n",
    "```octave\n",
    "cvx_begin quiet\n",
    "    variable x_con(200)\n",
    "    minimize norm(x_con - x_corrupt,2)\n",
    "    subject to\n",
    "        norm(x_con(2:200) - x_con(1:199),1) <= beta;\n",
    "cvx_end\n",
    "```\n",
    "\n",
    "Plot the reconstructed signal. In addition, by changing the beta, explain how beta affects in an optimization process. One of reconstructed signal with a proper value of beta is shown below:\n",
    "\n",
    "<img src=\"./image_files/problem08.png\", width = 400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7\n",
    "\n",
    "In this problem, we will try to classify handwritten digits. For the sake of simplicity, we simplify this digit classification problem into a binary classification between digit 0 and digit 1.\n",
    "\n",
    "### Step 1. Load the data\n",
    "\n",
    "|Data | Data dexcription |\n",
    "|---|---|\n",
    "|data0 |1000 images (28×28 pixels) of handwritten digit 0 |\n",
    "|data1 |1000 images (28×28 pixels) of handwritten digit 1 |\n",
    "\n",
    "<a href = \"https://www.dropbox.com/s/2perxs8nf4putzw/data0?dl=0\"> download data 0 </a>/ \n",
    "<a href = \"https://www.dropbox.com/s/s9lo2zjsg3cq3fu/data1?dl=0\"> download data 1 </a>read the files in Matlab\n",
    "\n",
    "To read the files in Matlab, use the following code: \n",
    "\n",
    "```octave\n",
    "fid = fopen('data0', 'r');\n",
    "[t1,N] = fread(fid,[28 28],'uchar');\n",
    "[t2,N] = fread(fid,[28 28],'uchar');\n",
    "```\n",
    "\n",
    "Here, we will load 1000 numbers of data from ‘data0’ and ‘data1’. To display the image use imshow(t1) or imagesc(t1).\n",
    "\n",
    "Note: make sure you are reading the files correctly. Check by displaying the first few and the last few images in each class.\n",
    "\n",
    "Note: calculations are more manageable if  you go though and convert each of the pixels in $28\\times28$ matrix to a binary value first. \n",
    "\n",
    "```octave\n",
    "% Convert to binary image\n",
    "t1 = t1 > 125;\n",
    "\n",
    "% or\n",
    "\n",
    "im2bw(t1)\n",
    "```\n",
    "\n",
    "### Step 2. Extract features\n",
    "\n",
    "Now we must select the own ‘features’ from image data to detect digit 0 and digit 1. Two features are recommended \n",
    "\n",
    "1)\tThe total average pixels located at the center of the image (`t1(10:19,10:19)`).\n",
    "\n",
    "2)\tThe total average pixels over the entire location. \n",
    "\n",
    "3)\tInclude the ones as our bias term.\n",
    "\n",
    "\n",
    "$$\\Phi(x) = \\begin{bmatrix}\\text{feature1}\\\\ \\text{feature2}\\\\ 1 \\end{bmatrix}$$\n",
    "\n",
    "You should end up with a $2000\\times3$ input matrix with the first $1000$ rows correspond to all of the ‘data0’ and the second 1000 rows correspond to the two features for all of the given ‘data1’. This matrix is matrix $\\Phi$  which we learned in a class.\n",
    "\n",
    "### Step 3. Plot the data\n",
    "Plot the data to see if classes are separable. The expected plot is the following: \n",
    "\n",
    "<img src=\"./image_files/problem02.png\", width = 400>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8\n",
    "\n",
    "We would like to use the perceptron algorithm to classify digit 0 and digit 1 in the training set.\n",
    "\t\n",
    "### Step 1. Initialization\n",
    "\n",
    "You have to initialize $\\omega$  . We usually set $\\omega$ to a zero vector as an initial guess.\n",
    "\n",
    "### Step 2. Update $\\omega$\n",
    "\n",
    "We update $\\omega$  when the prediction is wrong. The update rule is the following:  \n",
    "\n",
    "$$ \\omega \\leftarrow \\omega + y \\cdot x$$\n",
    "\n",
    "We will repeat the same iteration for the number of data points. Here’s a pseudo code:\n",
    "\n",
    "```\n",
    "For k = 1:100 {\n",
    "      For j = 1:100 {\n",
    "            i = random integer selection between 1 and 2000\n",
    "            compute yhat(i)\n",
    "            if yhat(i) is wrong {\n",
    "                w = w + y(i)x(i)\n",
    "            }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "For every $k’$s iteration, count and store how many predictions are wrong to see if your classifier converges to somewhere or not.\n",
    "\n",
    "### Step 3. Plot the result\n",
    "You are asked to plot two graphs. First, plot the number of wrong predictions with respect to every $k’$s iteration. The graph is expected as follows: \n",
    "\n",
    "<img src=\"./image_files/problem03.png\", width = 400>\n",
    "\n",
    "Second, plot the classifier (decision boundary). Note that the decision boundary is given: \n",
    "\n",
    "$$\\omega_1 x_1 + \\omega_2x_2 + \\omega_3 = 0$$\n",
    "\n",
    "The expected graph is the following\n",
    "\n",
    "<img src=\"./image_files/problem04.png\", width = 400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 9\n",
    "\n",
    "We would like to use the SVM to classify digit 0 and digit 1 in the training set instead of the perceptron.\n",
    "\n",
    "### Step 1. Define variables\n",
    "Find a classifier using the support vector machine which is equivalent to solving the following optimization problem:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{minimize } & \\lVert \\omega \\rVert_2 + \\gamma(1^Tu + 1^Tv)\\\\\n",
    "\\text{subject to }& \\\\\n",
    "& X^T \\omega + \\omega_0 \\geq 1 - u\\\\\n",
    "& Y^T \\omega + \\omega_0 \\leq - (1-v)\\\\\n",
    "& u \\geq 0\\\\\n",
    "& v \\geq 0\n",
    "\\end{align*}$$\n",
    "\n",
    "Here, $X$  and $Y$  are $1000\\times3$ matrix for each class. You can divide the above matrix $\\Phi$ into two parts to reuse it.\n",
    "\n",
    "### Step 2. CVX\n",
    "\n",
    "Run CVX to find  $\\omega$.\n",
    "\n",
    "### Step 3. Plot the result\n",
    "\n",
    "Now you have an optimal $\\omega$ . Plot a decision boundary. Note that our decision boundary is defined as follows: \n",
    "\n",
    "$$ \\omega_1 x_1 + \\omega_2 x_2 + \\omega_3 = 0$$\n",
    "\n",
    "The expected graph is: \n",
    "\n",
    "<img src=\"./image_files/problem05.png\", width = 400>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
